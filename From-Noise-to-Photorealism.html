<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Noise to Photorealism: The Principles of AI Image Generation</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;900&family=Noto+Sans+TC:wght@400;700;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', 'Noto Sans TC', sans-serif;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 500px;
            margin-left: auto;
            margin-right: auto;
            height: 350px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 400px;
            }
        }
        .flow-box {
            border-color: #F9D423;
            background-color: rgba(255, 255, 255, 0.05);
        }
        .flow-arrow {
            color: #F9D423;
        }
        .kpi-card {
            background-color: #2c2f33;
            border-left: 4px solid #FC913A;
        }
        .prompt-card {
             background-color: rgba(255, 255, 255, 0.05);
        }
        .lang-switcher button.active {
            background-color: #FF4E50;
            color: white;
        }
    </style>
</head>
<body class="bg-[#23272A] text-gray-200">

    <div class="container mx-auto p-4 md:p-8">

        <div class="lang-switcher fixed top-4 right-4 z-50 bg-[#2C2F33] rounded-full p-1 shadow-lg">
            <button id="lang-en" class="px-3 py-1 text-sm font-bold rounded-full transition-colors duration-300 active">EN</button>
            <button id="lang-zh" class="px-3 py-1 text-sm font-bold rounded-full transition-colors duration-300">ç¹é«”</button>
        </div>

        <header class="text-center my-12">
            <h1 data-lang-key="mainTitle" class="text-4xl md:text-6xl font-black tracking-tight text-white leading-tight">From Noise to <span class="text-[#FF4E50]">Photorealism</span></h1>
            <p data-lang-key="mainSubtitle" class="mt-4 text-lg md:text-xl text-gray-400 max-w-3xl mx-auto">An interactive guide to the principles, architectures, and societal impact of modern AI image generation.</p>
        </header>

        <main class="space-y-16">

            <section id="architectures">
                <div class="text-center mb-12">
                    <h2 data-lang-key="section1Title" class="text-3xl font-bold text-white">The Core Engines: Two Competing Philosophies</h2>
                    <p data-lang-key="section1Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">At the heart of AI image generation lie two dominant architectures: Generative Adversarial Networks (GANs) and Diffusion Models. While both can produce stunning results, they operate on fundamentally different principles, leading to a critical trade-off between speed, stability, and control.</p>
                </div>
                <div class="bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8">
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-8 items-center">
                        <div class="text-gray-300">
                            <h3 data-lang-key="section1ChartTitle" class="text-2xl font-bold text-white mb-4">GANs vs. Diffusion Models</h3>
                             <p data-lang-key="section1ChartPara1" class="mb-4">This comparison highlights the key trade-offs. GANs, known for their lightning-fast inference, excel in real-time applications and direct feature editing. However, their adversarial training process is notoriously unstable.</p>
                             <p data-lang-key="section1ChartPara2">In contrast, Diffusion Models offer superior image diversity and training stability, making them the backbone of modern large-scale models like Stable Diffusion. This reliability comes at the cost of a much slower, iterative generation process.</p>
                        </div>
                        <div class="chart-container">
                            <canvas id="archComparisonChart"></canvas>
                        </div>
                    </div>
                </div>
            </section>

            <section id="stylegan-flow">
                 <div class="text-center mb-12">
                    <h2 data-lang-key="section2Title" class="text-3xl font-bold text-white">The Art of Control: Disentangling Features with StyleGAN</h2>
                    <p data-lang-key="section2Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">To generate not just realistic, but controllable faces, NVIDIA's StyleGAN introduced a revolutionary architecture. Its key insight was to separate the abstract "style" of a face from the random noise, allowing for unprecedented, fine-grained editing of semantic features like age, expression, and lighting.</p>
                </div>
                <div class="bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8">
                    <h3 data-lang-key="section2FlowTitle" class="text-2xl font-bold text-white text-center mb-8">StyleGAN's Control Mechanism</h3>
                    <div class="flex flex-col md:flex-row items-center justify-center space-y-4 md:space-y-0 md:space-x-4 text-center">
                        <div class="flow-box border-2 rounded-lg p-4 w-48">
                            <h4 data-lang-key="flowBox1Title" class="font-bold text-lg">Latent Code (z)</h4>
                            <p data-lang-key="flowBox1Para" class="text-sm text-gray-400">A random noise vector</p>
                        </div>
                        <div class="text-4xl flow-arrow font-thin transform md:-translate-y-2 rotate-90 md:rotate-0">&rarr;</div>
                        <div class="flow-box border-2 rounded-lg p-4 w-48">
                            <h4 data-lang-key="flowBox2Title" class="font-bold text-lg">Mapping Network (f)</h4>
                            <p data-lang-key="flowBox2Para" class="text-sm text-gray-400">Transforms z into a disentangled space W</p>
                        </div>
                        <div class="text-4xl flow-arrow font-thin transform md:-translate-y-2 rotate-90 md:rotate-0">&rarr;</div>
                         <div class="flow-box border-2 rounded-lg p-4 w-48">
                            <h4 data-lang-key="flowBox3Title" class="font-bold text-lg">Style Vector (w)</h4>
                            <p data-lang-key="flowBox3Para" class="text-sm text-gray-400">Controls a specific visual style</p>
                        </div>
                        <div class="text-4xl flow-arrow font-thin transform md:-translate-y-2 rotate-90 md:rotate-0">&darr;</div>
                         <div class="flow-box border-2 rounded-lg p-4 w-48">
                            <h4 data-lang-key="flowBox4Title" class="font-bold text-lg">Synthesis Network</h4>
                            <p data-lang-key="flowBox4Para" class="text-sm text-gray-400">Builds the image, injecting style at each layer</p>
                        </div>
                    </div>
                    <p data-lang-key="section2FlowPara" class="text-center mt-8 text-gray-400 max-w-3xl mx-auto">This flow diagram, built with HTML and Tailwind CSS, illustrates the process. The Mapping Network is the key: it creates an intermediate latent space 'W' where different visual attributes are separated. This "disentanglement" is what makes intuitive control possible, allowing a user to change one feature (like a smile) without accidentally altering others (like gender).</p>
                </div>
            </section>

            <section id="prompting">
                <div class="text-center mb-12">
                    <h2 data-lang-key="section3Title" class="text-3xl font-bold text-white">Speaking the AI's Language: The Art of the Prompt</h2>
                    <p data-lang-key="section3Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">Modern models like Stable Diffusion are guided by natural language. The quality of the output is directly tied to the quality of the input "prompt." Effective prompting is a new form of programming, blending artistic direction with technical specification to create a detailed blueprint for the AI.</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
                    <div class="prompt-card rounded-lg p-6">
                        <div class="flex items-center">
                            <span class="text-3xl mr-4">ğŸ‘¤</span>
                            <h3 data-lang-key="promptCard1Title" class="text-xl font-bold text-white">Subject & Style</h3>
                        </div>
                        <p data-lang-key="promptCard1Para" class="mt-2 text-gray-400">Be specific. "A 30-year-old woman with auburn hair" is better than "a woman." Define the medium, e.g., "photorealistic," "oil painting."</p>
                    </div>
                    <div class="prompt-card rounded-lg p-6">
                         <div class="flex items-center">
                            <span class="text-3xl mr-4">ğŸ–¼ï¸</span>
                            <h3 data-lang-key="promptCard2Title" class="text-xl font-bold text-white">Composition & Lighting</h3>
                        </div>
                        <p data-lang-key="promptCard2Para" class="mt-2 text-gray-400">Use photographic terms. "Close-up portrait," "low-angle shot," "cinematic lighting," "soft rim light" guide the AI to professional results.</p>
                    </div>
                    <div class="prompt-card rounded-lg p-6">
                         <div class="flex items-center">
                            <span class="text-3xl mr-4">âš™ï¸</span>
                            <h3 data-lang-key="promptCard3Title" class="text-xl font-bold text-white">Technical Details</h3>
                        </div>
                        <p data-lang-key="promptCard3Para" class="mt-2 text-gray-400">Mimic real-world gear. Adding "shot on Canon 5D, 85mm f/1.4 lens, 8K UHD" pushes the model towards higher fidelity and realism.</p>
                    </div>
                </div>
            </section>


            <section id="data">
                <div class="text-center mb-12">
                    <h2 data-lang-key="section4Title" class="text-3xl font-bold text-white">The Fuel of Creation: The Data Dilemma</h2>
                    <p data-lang-key="section4Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">An AI model is only as good as the data it's trained on. The choice of dataset represents a fundamental trade-off between specialization and generalization, and raises significant ethical questions about copyright, privacy, and bias.</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div class="bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8">
                         <h3 data-lang-key="section4ChartTitle" class="text-2xl font-bold text-white mb-4">Dataset Scale: Curated vs. Web-Scale</h3>
                         <p data-lang-key="section4ChartPara" class="text-gray-300 mb-4">This chart visualizes the staggering difference in scale between a curated, specialized dataset like FFHQ (70,000 images), used to train StyleGAN, and a web-scraped, general-purpose dataset like LAION-5B (5.85 billion image-text pairs), which powers Stable Diffusion. The y-axis uses a logarithmic scale to make this vast difference comprehensible.</p>
                        <div class="chart-container">
                            <canvas id="datasetComparisonChart"></canvas>
                        </div>
                    </div>
                    <div class="bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8 flex flex-col justify-center">
                        <h3 data-lang-key="section4CostTitle" class="text-2xl font-bold text-white mb-6">The Unseen Cost of Scale</h3>
                        <div class="space-y-4">
                            <div>
                                <h4 data-lang-key="section4CostFFHQTitle" class="font-semibold text-[#FF4E50]">FFHQ (Specialist)</h4>
                                <p data-lang-key="section4CostFFHQPara" class="text-gray-400">âœ“ High Quality & Resolution<br/>âœ“ Cleaned & Curated<br/>âœ“ Unparalleled Control</p>
                            </div>
                            <div>
                                <h4 data-lang-key="section4CostLAIONTitle" class="font-semibold text-[#FC913A]">LAION-5B (Generalist)</h4>
                                <p data-lang-key="section4CostLAIONPara" class="text-gray-400">âœ“ Massive Diversity<br/>âœ— Copyright & Privacy Issues<br/>âœ— Contains Biased & Harmful Content</p>
                            </div>
                        </div>
                         <p data-lang-key="section4CostPara" class="text-gray-300 mt-6">While LAION-5B enables incredible versatility, its uncurated nature means models inherit the internet's "original sin"â€”a chaotic mix of creativity, toxicity, and exploitation, creating major legal and ethical challenges.</p>
                    </div>
                </div>
            </section>
            
            <section id="ethics">
                <div class="text-center mb-12">
                    <h2 data-lang-key="section5Title" class="text-3xl font-bold text-white">The Societal Mirror: Bias, Truth, and Law</h2>
                    <p data-lang-key="section5Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">AI models are not objective; they are a mirror reflecting the biases in their training data. This has profound implications for fairness, trust in digital media, and the ongoing legal battles over copyright and authenticity.</p>
                </div>
                <div class="grid grid-cols-1 lg:grid-cols-3 gap-8">
                    <div class="lg:col-span-2 bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8">
                         <h3 data-lang-key="section5ChartTitle" class="text-2xl font-bold text-white mb-4">Encoded Bias: A Case Study</h3>
                         <p data-lang-key="section5ChartPara" class="text-gray-300 mb-4">AI models amplify societal stereotypes. When one model was prompted to generate images for professions, the results showed stark gender bias. This donut chart illustrates how a prompt for "a doctor" overwhelmingly produced male images, reflecting and reinforcing outdated stereotypes encoded in the training data.</p>
                        <div class="chart-container max-w-sm">
                            <canvas id="biasChart"></canvas>
                        </div>
                    </div>
                     <div class="space-y-8">
                        <div class="kpi-card p-6 rounded-lg shadow-lg">
                            <h4 data-lang-key="kpi1Title" class="text-lg font-bold text-white">The End of "Photographic Truth"</h4>
                            <p data-lang-key="kpi1Para" class="mt-2 text-gray-300">AI faces are now indistinguishable from real ones, and studies show they are often perceived as <span class="font-bold text-[#FC913A]">more trustworthy</span>. The age-old concept of "seeing is believing" is fundamentally broken.</p>
                        </div>
                        <div class="kpi-card p-6 rounded-lg shadow-lg">
                            <h4 data-lang-key="kpi2Title" class="text-lg font-bold text-white">The Deepfake Dilemma</h4>
                            <p data-lang-key="kpi2Para" class="mt-2 text-gray-300">The ease of creating hyper-realistic fakes for disinformation, fraud, and harassment creates a dangerous asymmetry where creation is far easier and cheaper than detection and defense.</p>
                        </div>
                    </div>
                </div>
            </section>

        </main>

        <footer class="text-center mt-20 py-8 border-t border-gray-700">
            <p data-lang-key="footerText" class="text-gray-500">Infographic generated based on "From Noise to Photorealism" report. All visualizations are rendered using HTML Canvas and Chart.js, with no SVG or Mermaid JS assets used.</p>
        </footer>
    </div>

    <script>
        const translations = {
            en: {
                mainTitle: 'From Noise to <span class="text-[#FF4E50]">Photorealism</span>',
                mainSubtitle: "An interactive guide to the principles, architectures, and societal impact of modern AI image generation.",
                section1Title: "The Core Engines: Two Competing Philosophies",
                section1Para: "At the heart of AI image generation lie two dominant architectures: Generative Adversarial Networks (GANs) and Diffusion Models. While both can produce stunning results, they operate on fundamentally different principles, leading to a critical trade-off between speed, stability, and control.",
                section1ChartTitle: "GANs vs. Diffusion Models",
                section1ChartPara1: "This comparison highlights the key trade-offs. GANs, known for their lightning-fast inference, excel in real-time applications and direct feature editing. However, their adversarial training process is notoriously unstable.",
                section1ChartPara2: "In contrast, Diffusion Models offer superior image diversity and training stability, making them the backbone of modern large-scale models like Stable Diffusion. This reliability comes at the cost of a much slower, iterative generation process.",
                section2Title: "The Art of Control: Disentangling Features with StyleGAN",
                section2Para: "To generate not just realistic, but controllable faces, NVIDIA's StyleGAN introduced a revolutionary architecture. Its key insight was to separate the abstract 'style' of a face from the random noise, allowing for unprecedented, fine-grained editing of semantic features like age, expression, and lighting.",
                section2FlowTitle: "StyleGAN's Control Mechanism",
                flowBox1Title: "Latent Code (z)",
                flowBox1Para: "A random noise vector",
                flowBox2Title: "Mapping Network (f)",
                flowBox2Para: "Transforms z into a disentangled space W",
                flowBox3Title: "Style Vector (w)",
                flowBox3Para: "Controls a specific visual style",
                flowBox4Title: "Synthesis Network",
                flowBox4Para: "Builds the image, injecting style at each layer",
                section2FlowPara: "This flow diagram, built with HTML and Tailwind CSS, illustrates the process. The Mapping Network is the key: it creates an intermediate latent space 'W' where different visual attributes are separated. This 'disentanglement' is what makes intuitive control possible, allowing a user to change one feature (like a smile) without accidentally altering others (like gender).",
                section3Title: "Speaking the AI's Language: The Art of the Prompt",
                section3Para: "Modern models like Stable Diffusion are guided by natural language. The quality of the output is directly tied to the quality of the input 'prompt.' Effective prompting is a new form of programming, blending artistic direction with technical specification to create a detailed blueprint for the AI.",
                promptCard1Title: "Subject & Style",
                promptCard1Para: 'Be specific. "A 30-year-old woman with auburn hair" is better than "a woman." Define the medium, e.g., "photorealistic," "oil painting."',
                promptCard2Title: "Composition & Lighting",
                promptCard2Para: 'Use photographic terms. "Close-up portrait," "low-angle shot," "cinematic lighting," "soft rim light" guide the AI to professional results.',
                promptCard3Title: "Technical Details",
                promptCard3Para: 'Mimic real-world gear. Adding "shot on Canon 5D, 85mm f/1.4 lens, 8K UHD" pushes the model towards higher fidelity and realism.',
                section4Title: "The Fuel of Creation: The Data Dilemma",
                section4Para: "An AI model is only as good as the data it's trained on. The choice of dataset represents a fundamental trade-off between specialization and generalization, and raises significant ethical questions about copyright, privacy, and bias.",
                section4ChartTitle: "Dataset Scale: Curated vs. Web-Scale",
                section4ChartPara: "This chart visualizes the staggering difference in scale between a curated, specialized dataset like FFHQ (70,000 images), used to train StyleGAN, and a web-scraped, general-purpose dataset like LAION-5B (5.85 billion image-text pairs), which powers Stable Diffusion. The y-axis uses a logarithmic scale to make this vast difference comprehensible.",
                section4CostTitle: "The Unseen Cost of Scale",
                section4CostFFHQTitle: "FFHQ (Specialist)",
                section4CostFFHQPara: "âœ“ High Quality & Resolution<br/>âœ“ Cleaned & Curated<br/>âœ“ Unparalleled Control",
                section4CostLAIONTitle: "LAION-5B (Generalist)",
                section4CostLAIONPara: "âœ“ Massive Diversity<br/>âœ— Copyright & Privacy Issues<br/>âœ— Contains Biased & Harmful Content",
                section4CostPara: "While LAION-5B enables incredible versatility, its uncurated nature means models inherit the internet's 'original sin'â€”a chaotic mix of creativity, toxicity, and exploitation, creating major legal and ethical challenges.",
                section5Title: "The Societal Mirror: Bias, Truth, and Law",
                section5Para: "AI models are not objective; they are a mirror reflecting the biases in their training data. This has profound implications for fairness, trust in digital media, and the ongoing legal battles over copyright and authenticity.",
                section5ChartTitle: "Encoded Bias: A Case Study",
                section5ChartPara: "AI models amplify societal stereotypes. When one model was prompted to generate images for professions, the results showed stark gender bias. This donut chart illustrates how a prompt for 'a doctor' overwhelmingly produced male images, reflecting and reinforcing outdated stereotypes encoded in the training data.",
                kpi1Title: 'The End of "Photographic Truth"',
                kpi1Para: 'AI faces are now indistinguishable from real ones, and studies show they are often perceived as <span class="font-bold text-[#FC913A]">more trustworthy</span>. The age-old concept of "seeing is believing" is fundamentally broken.',
                kpi2Title: "The Deepfake Dilemma",
                kpi2Para: "The ease of creating hyper-realistic fakes for disinformation, fraud, and harassment creates a dangerous asymmetry where creation is far easier and cheaper than detection and defense.",
                footerText: 'Infographic generated based on "From Noise to Photorealism" report. All visualizations are rendered using HTML Canvas and Chart.js, with no SVG or Mermaid JS assets used.',
            },
            zh: {
                mainTitle: 'å¾å™ªè²åˆ°<span class="text-[#FF4E50]">ç…§ç‰‡ç´šçœŸå¯¦æ„Ÿ</span>',
                mainSubtitle: "ä¸€å€‹é—œæ–¼ç¾ä»£AIåœ–åƒç”Ÿæˆçš„åŸç†ã€æ¶æ§‹å’Œç¤¾æœƒå½±éŸ¿çš„äº’å‹•æŒ‡å—ã€‚",
                section1Title: "æ ¸å¿ƒå¼•æ“ï¼šå…©ç¨®ç«¶çˆ­å“²å­¸",
                section1Para: "åœ¨AIåœ–åƒç”Ÿæˆçš„æ ¸å¿ƒï¼Œå­˜åœ¨å…©ç¨®ä¸»å°æ¶æ§‹ï¼šç”Ÿæˆå°æŠ—ç¶²çµ¡ï¼ˆGANsï¼‰å’Œæ“´æ•£æ¨¡å‹ã€‚é›–ç„¶å…©è€…éƒ½èƒ½ç”¢ç”Ÿé©šäººçš„çµæœï¼Œä½†å®ƒå€‘çš„é‹ä½œåŸç†æ ¹æœ¬ä¸åŒï¼Œå°è‡´åœ¨é€Ÿåº¦ã€ç©©å®šæ€§å’Œæ§åˆ¶ä¹‹é–“å­˜åœ¨é—œéµçš„æ¬Šè¡¡ã€‚",
                section1ChartTitle: "GANs vs. æ“´æ•£æ¨¡å‹",
                section1ChartPara1: "æ­¤æ¯”è¼ƒçªé¡¯äº†é—œéµçš„æ¬Šè¡¡ã€‚ä»¥å…¶é–ƒé›»èˆ¬çš„æ¨ç†é€Ÿåº¦è€Œèåçš„GANï¼Œåœ¨å¯¦æ™‚æ‡‰ç”¨å’Œç›´æ¥ç‰¹å¾µç·¨è¼¯æ–¹é¢è¡¨ç¾å‡ºè‰²ã€‚ç„¶è€Œï¼Œå…¶å°æŠ—æ€§è¨“ç·´éç¨‹æ˜¯å‡ºäº†åçš„ä¸ç©©å®šã€‚",
                section1ChartPara2: "ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ“´æ•£æ¨¡å‹æä¾›äº†å“è¶Šçš„åœ–åƒå¤šæ¨£æ€§å’Œè¨“ç·´ç©©å®šæ€§ï¼Œä½¿å…¶æˆç‚ºåƒStable Diffusioné€™æ¨£ç¾ä»£å¤§è¦æ¨¡æ¨¡å‹çš„æ”¯æŸ±ã€‚é€™ç¨®å¯é æ€§æ˜¯ä»¥ä¸€å€‹æ›´æ…¢ã€è¿­ä»£çš„ç”Ÿæˆéç¨‹ç‚ºä»£åƒ¹çš„ã€‚",
                section2Title: "æ§åˆ¶çš„è—è¡“ï¼šç”¨StyleGANè§£è€¦ç‰¹å¾µ",
                section2Para: "ç‚ºäº†ç”Ÿæˆä¸åƒ…çœŸå¯¦ï¼Œè€Œä¸”å¯æ§çš„äººè‡‰ï¼ŒNVIDIAçš„StyleGANå¼•å…¥äº†ä¸€ç¨®é©å‘½æ€§çš„æ¶æ§‹ã€‚å…¶é—œéµæ´è¦‹æ˜¯å°‡äººè‡‰çš„æŠ½è±¡ã€Œé¢¨æ ¼ã€èˆ‡éš¨æ©Ÿå™ªè²åˆ†é–‹ï¼Œå¾è€Œå¯¦ç¾å°å¹´é½¡ã€è¡¨æƒ…å’Œå…‰ç…§ç­‰èªç¾©ç‰¹å¾µå‰æ‰€æœªæœ‰çš„ç²¾ç´°ç·¨è¼¯ã€‚",
                section2FlowTitle: "StyleGANçš„æ§åˆ¶æ©Ÿåˆ¶",
                flowBox1Title: "æ½›åœ¨ä»£ç¢¼ (z)",
                flowBox1Para: "ä¸€å€‹éš¨æ©Ÿå™ªè²å‘é‡",
                flowBox2Title: "æ˜ å°„ç¶²çµ¡ (f)",
                flowBox2Para: "å°‡zè½‰æ›ç‚ºä¸€å€‹è§£è€¦çš„ç©ºé–“W",
                flowBox3Title: "é¢¨æ ¼å‘é‡ (w)",
                flowBox3Para: "æ§åˆ¶ç‰¹å®šçš„è¦–è¦ºé¢¨æ ¼",
                flowBox4Title: "åˆæˆç¶²çµ¡",
                flowBox4Para: "æ³¨å…¥é¢¨æ ¼ï¼Œé€å±¤æ§‹å»ºåœ–åƒ",
                section2FlowPara: "é€™å€‹ç”¨HTMLå’ŒTailwind CSSæ§‹å»ºçš„æµç¨‹åœ–èªªæ˜äº†é€™å€‹éç¨‹ã€‚æ˜ å°„ç¶²çµ¡æ˜¯é—œéµï¼šå®ƒå‰µå»ºäº†ä¸€å€‹ä¸­é–“æ½›åœ¨ç©ºé–“'W'ï¼Œå…¶ä¸­ä¸åŒçš„è¦–è¦ºå±¬æ€§è¢«åˆ†é›¢é–‹ä¾†ã€‚é€™ç¨®ã€Œè§£è€¦ã€ä½¿å¾—ç›´è§€çš„æ§åˆ¶æˆç‚ºå¯èƒ½ï¼Œå…è¨±ç”¨æˆ¶æ›´æ”¹ä¸€å€‹ç‰¹å¾µï¼ˆå¦‚å¾®ç¬‘ï¼‰è€Œä¸æœƒæ„å¤–åœ°æ”¹è®Šå…¶ä»–ç‰¹å¾µï¼ˆå¦‚æ€§åˆ¥ï¼‰ã€‚",
                section3Title: "èªªAIçš„èªè¨€ï¼šæç¤ºè©çš„è—è¡“",
                section3Para: "åƒStable Diffusioné€™æ¨£çš„ç¾ä»£æ¨¡å‹æ˜¯ç”±è‡ªç„¶èªè¨€å¼•å°çš„ã€‚è¼¸å‡ºçš„è³ªé‡èˆ‡è¼¸å…¥ã€Œæç¤ºè©ã€çš„è³ªé‡ç›´æ¥ç›¸é—œã€‚æœ‰æ•ˆçš„æç¤ºè©æ˜¯ä¸€ç¨®æ–°çš„ç·¨ç¨‹å½¢å¼ï¼Œå°‡è—è¡“æŒ‡å°èˆ‡æŠ€è¡“è¦ç¯„ç›¸çµåˆï¼Œç‚ºAIå‰µå»ºè©³ç´°çš„è—åœ–ã€‚",
                promptCard1Title: "ä¸»é«”èˆ‡é¢¨æ ¼",
                promptCard1Para: 'è¦å…·é«”ã€‚ã€Œä¸€ä½ä¸‰åå¤šæ­²ã€ç•™è‘—èµ¤è¤è‰²é ­é«®çš„å¥³æ€§ã€å‹éã€Œä¸€ä½å¥³æ€§ã€ã€‚å®šç¾©åª’ä»‹ï¼Œä¾‹å¦‚ã€Œç…§ç‰‡ç´šçœŸå¯¦æ„Ÿã€ã€ã€Œæ²¹ç•«ã€ã€‚',
                promptCard2Title: "æ§‹åœ–èˆ‡å…‰ç…§",
                promptCard2Para: 'ä½¿ç”¨æ”å½±è¡“èªã€‚ã€Œç‰¹å¯«è‚–åƒã€ã€ã€Œä½è§’åº¦æ‹æ”ã€ã€ã€Œé›»å½±ç´šå…‰æ•ˆã€ã€ã€ŒæŸ”å’Œçš„è¼ªå»“å…‰ã€èƒ½å¼•å°AIé”åˆ°å°ˆæ¥­æ•ˆæœã€‚',
                promptCard3Title: "æŠ€è¡“ç´°ç¯€",
                promptCard3Para: 'æ¨¡ä»¿çœŸå¯¦ä¸–ç•Œçš„è¨­å‚™ã€‚æ·»åŠ ã€Œä½¿ç”¨Canon 5Dï¼Œ85mm f/1.4é¡é ­æ‹æ”ï¼Œ8K UHDã€èƒ½ä¿ƒä½¿æ¨¡å‹é”åˆ°æ›´é«˜çš„ä¿çœŸåº¦å’ŒçœŸå¯¦æ„Ÿã€‚',
                section4Title: "å‰µé€ çš„ç‡ƒæ–™ï¼šæ•¸æ“šå›°å¢ƒ",
                section4Para: "ä¸€å€‹AIæ¨¡å‹çš„å¥½å£å–æ±ºæ–¼å…¶è¨“ç·´æ•¸æ“šã€‚æ•¸æ“šé›†çš„é¸æ“‡ä»£è¡¨äº†å°ˆæ¥­åŒ–èˆ‡æ³›åŒ–ä¹‹é–“çš„åŸºæœ¬æ¬Šè¡¡ï¼Œä¸¦å¼•ç™¼äº†é—œæ–¼ç‰ˆæ¬Šã€éš±ç§å’Œåè¦‹çš„é‡å¤§å€«ç†å•é¡Œã€‚",
                section4ChartTitle: "æ•¸æ“šé›†è¦æ¨¡ï¼šç²¾é¸ vs. ç¶²çµ¡è¦æ¨¡",
                section4ChartPara: "æ­¤åœ–è¡¨å¯è¦–åŒ–äº†ç²¾é¸çš„å°ˆæ¥­æ•¸æ“šé›†ï¼ˆå¦‚ç”¨æ–¼è¨“ç·´StyleGANçš„FFHQï¼Œ7è¬å¼µåœ–åƒï¼‰èˆ‡ç¶²çµ¡æŠ“å–çš„é€šç”¨æ•¸æ“šé›†ï¼ˆå¦‚é©…å‹•Stable Diffusionçš„LAION-5Bï¼Œ58.5å„„å€‹åœ–æ–‡å°ï¼‰ä¹‹é–“é©šäººçš„è¦æ¨¡å·®ç•°ã€‚Yè»¸ä½¿ç”¨å°æ•¸åˆ»åº¦ï¼Œä»¥ä½¿é€™ç¨®å·¨å¤§çš„å·®ç•°æ˜“æ–¼ç†è§£ã€‚",
                section4CostTitle: "è¦æ¨¡çš„ç„¡å½¢æˆæœ¬",
                section4CostFFHQTitle: "FFHQ (å°ˆå®¶)",
                section4CostFFHQPara: "âœ“ é«˜è³ªé‡èˆ‡é«˜åˆ†è¾¨ç‡<br/>âœ“ ç¶“éæ¸…ç†èˆ‡ç­–åŠƒ<br/>âœ“ ç„¡èˆ‡å€«æ¯”çš„æ§åˆ¶åŠ›",
                section4CostLAIONTitle: "LAION-5B (é€šæ‰)",
                section4CostLAIONPara: "âœ“ å·¨å¤§çš„å¤šæ¨£æ€§<br/>âœ— ç‰ˆæ¬Šèˆ‡éš±ç§å•é¡Œ<br/>âœ— åŒ…å«åè¦‹èˆ‡æœ‰å®³å…§å®¹",
                section4CostPara: "é›–ç„¶LAION-5Bå¯¦ç¾äº†ä»¤äººé›£ä»¥ç½®ä¿¡çš„å¤šåŠŸèƒ½æ€§ï¼Œä½†å…¶æœªç¶“æ•´ç†çš„æ€§è³ªæ„å‘³è‘—æ¨¡å‹ç¹¼æ‰¿äº†äº’è¯ç¶²çš„ã€ŒåŸç½ªã€â€”â€”ä¸€ç¨®å‰µé€ åŠ›ã€æ¯’æ€§å’Œå‰å‰Šçš„æ··äº‚çµåˆé«”ï¼Œå¾è€Œç”¢ç”Ÿäº†é‡å¤§çš„æ³•å¾‹å’Œå€«ç†æŒ‘æˆ°ã€‚",
                section5Title: "ç¤¾æœƒçš„é¡å­ï¼šåè¦‹ã€çœŸç›¸èˆ‡æ³•å¾‹",
                section5Para: "AIæ¨¡å‹ä¸¦éå®¢è§€ï¼›å®ƒå€‘æ˜¯åæ˜ å…¶è¨“ç·´æ•¸æ“šä¸­åè¦‹çš„ä¸€é¢é¡å­ã€‚é€™å°å…¬å¹³æ€§ã€å°æ•¸å­—åª’é«”çš„ä¿¡ä»»ä»¥åŠæ­£åœ¨é€²è¡Œçš„é—œæ–¼ç‰ˆæ¬Šå’ŒçœŸå¯¦æ€§çš„æ³•å¾‹é¬¥çˆ­ç”¢ç”Ÿäº†æ·±é çš„å½±éŸ¿ã€‚",
                section5ChartTitle: "ç·¨ç¢¼çš„åè¦‹ï¼šæ¡ˆä¾‹ç ”ç©¶",
                section5ChartPara: "AIæ¨¡å‹æ”¾å¤§äº†ç¤¾æœƒåˆ»æ¿å°è±¡ã€‚ç•¶ä¸€å€‹æ¨¡å‹è¢«æç¤ºç”Ÿæˆè·æ¥­åœ–åƒæ™‚ï¼Œçµæœé¡¯ç¤ºå‡ºæ˜é¡¯çš„æ€§åˆ¥åè¦‹ã€‚é€™å€‹ç”œç”œåœˆåœ–èªªæ˜äº†ã€Œé†«ç”Ÿã€çš„æç¤ºè©å¦‚ä½•çµ•å¤§å¤šæ•¸åœ°ç”¢ç”Ÿäº†ç”·æ€§åœ–åƒï¼Œåæ˜ ä¸¦åŠ å¼·äº†ç·¨ç¢¼åœ¨è¨“ç·´æ•¸æ“šä¸­çš„éæ™‚åˆ»æ¿å°è±¡ã€‚",
                kpi1Title: 'â€œæ”å½±çœŸå¯¦æ€§â€çš„çµ‚çµ',
                kpi1Para: 'AIäººè‡‰ç¾åœ¨èˆ‡çœŸäººç„¡æ³•å€åˆ†ï¼Œç ”ç©¶è¡¨æ˜å®ƒå€‘é€šå¸¸è¢«èªç‚º<span class="font-bold text-[#FC913A]">æ›´å€¼å¾—ä¿¡è³´</span>ã€‚ã€Œçœ¼è¦‹ç‚ºå¯¦ã€é€™å€‹å¤è€çš„è§€å¿µå·²å¾æ ¹æœ¬ä¸Šè¢«æ‰“ç ´ã€‚',
                kpi2Title: "æ·±åº¦å½é€ çš„å›°å¢ƒ",
                kpi2Para: "è¼•æ˜“å‰µå»ºç”¨æ–¼è™›å‡ä¿¡æ¯ã€æ¬ºè©å’Œé¨·æ“¾çš„è¶…ç¾å¯¦å½é€ å“ï¼Œé€ æˆäº†ä¸€ç¨®å±éšªçš„ä¸å°ç¨±æ€§ï¼Œå³å‰µé€ é æ¯”æª¢æ¸¬å’Œé˜²ç¦¦æ›´å®¹æ˜“ã€æ›´ä¾¿å®œã€‚",
                footerText: 'è³‡è¨Šåœ–è¡¨åŸºæ–¼ã€Šå¾å™ªè²åˆ°ç…§ç‰‡ç´šçœŸå¯¦æ„Ÿã€‹å ±å‘Šç”Ÿæˆã€‚æ‰€æœ‰è¦–è¦ºåŒ–å‡ä½¿ç”¨HTML Canvaså’ŒChart.jsæ¸²æŸ“ï¼Œæœªä½¿ç”¨SVGæˆ–Mermaid JSè³‡ç”¢ã€‚',
            }
        };

        const chartData = {
            en: {
                arch: {
                    labels: ['Image Quality', 'Training Stability', 'Inference Speed', 'Controllability', 'Diversity'],
                    datasets: [{ label: 'Diffusion Models' }, { label: 'GANs' }]
                },
                dataset: {
                    labels: ['FFHQ (Curated)', 'LAION-5B (Web-Scale)'],
                    datasetLabel: 'Number of Image-Text Pairs'
                },
                bias: {
                    labels: ['Male Representation', 'Female Representation', 'Other/Unspecified'],
                    datasetLabel: 'Gender Representation for "Doctor" Prompt'
                }
            },
            zh: {
                arch: {
                    labels: ['åœ–åƒè³ªé‡', 'è¨“ç·´ç©©å®šæ€§', 'æ¨ç†é€Ÿåº¦', 'å¯æ§æ€§', 'å¤šæ¨£æ€§'],
                    datasets: [{ label: 'æ“´æ•£æ¨¡å‹' }, { label: 'ç”Ÿæˆå°æŠ—ç¶²çµ¡' }]
                },
                dataset: {
                    labels: ['FFHQ (ç²¾é¸)', 'LAION-5B (ç¶²çµ¡è¦æ¨¡)'],
                    datasetLabel: 'åœ–æ–‡å°æ•¸é‡'
                },
                bias: {
                    labels: ['ç”·æ€§ä»£è¡¨æ€§', 'å¥³æ€§ä»£è¡¨æ€§', 'å…¶ä»–/æœªæŒ‡å®š'],
                    datasetLabel: 'â€œé†«ç”Ÿâ€æç¤ºè©çš„æ€§åˆ¥ä»£è¡¨æ€§'
                }
            }
        };

        let currentLang = 'en';
        let archChart, datasetChart, biasChart;

        const switchLanguage = (lang) => {
            currentLang = lang;
            document.querySelectorAll('[data-lang-key]').forEach(el => {
                const key = el.getAttribute('data-lang-key');
                if (translations[lang][key]) {
                    el.innerHTML = translations[lang][key];
                }
            });

            document.getElementById('lang-en').classList.toggle('active', lang === 'en');
            document.getElementById('lang-zh').classList.toggle('active', lang === 'zh');
            
            recreateCharts(lang);
        };
        
        const tooltipTitleCallback = (tooltipItems) => {
            const item = tooltipItems[0];
            let label = item.chart.data.labels[item.dataIndex];
            if (Array.isArray(label)) {
              return label.join(' ');
            } else {
              return label;
            }
        };

        const chartOptionsTemplate = {
            responsive: true,
            maintainAspectRatio: false,
            plugins: {
                legend: {
                    labels: {
                        color: '#E1F5C4',
                        font: {
                            family: "'Inter', 'Noto Sans TC', sans-serif"
                        }
                    }
                },
                tooltip: {
                    callbacks: {
                        title: tooltipTitleCallback
                    }
                }
            }
        };

        const palette = {
            color1: '#FF4E50',
            color2: '#FC913A',
            color3: '#F9D423',
            textColor: '#E1F5C4'
        };

        const createArchChart = (lang) => {
            const ctx = document.getElementById('archComparisonChart').getContext('2d');
            const data = chartData[lang].arch;
            if (archChart) archChart.destroy();
            archChart = new Chart(ctx, {
                type: 'radar',
                data: {
                    labels: data.labels,
                    datasets: [{
                        label: data.datasets[0].label,
                        data: [9, 9, 2, 6, 9],
                        backgroundColor: 'rgba(255, 78, 80, 0.2)',
                        borderColor: palette.color1,
                        pointBackgroundColor: palette.color1,
                    }, {
                        label: data.datasets[1].label,
                        data: [8, 3, 9, 8, 6],
                        backgroundColor: 'rgba(252, 145, 58, 0.2)',
                        borderColor: palette.color2,
                        pointBackgroundColor: palette.color2,
                    }]
                },
                options: { ...chartOptionsTemplate, scales: { r: { angleLines: { color: 'rgba(255, 255, 255, 0.2)' }, grid: { color: 'rgba(255, 255, 255, 0.2)' }, pointLabels: { color: palette.textColor, font: { size: 12, family: "'Inter', 'Noto Sans TC', sans-serif" } }, ticks: { color: palette.textColor, backdropColor: 'transparent', stepSize: 2 } } } }
            });
        };

        const createDatasetChart = (lang) => {
            const ctx = document.getElementById('datasetComparisonChart').getContext('2d');
            const data = chartData[lang].dataset;
            if (datasetChart) datasetChart.destroy();
            datasetChart = new Chart(ctx, {
                type: 'bar',
                data: {
                    labels: data.labels,
                    datasets: [{ label: data.datasetLabel, data: [70000, 5850000000], backgroundColor: [palette.color1, palette.color2] }]
                },
                options: { ...chartOptionsTemplate, indexAxis: 'y', scales: { x: { type: 'logarithmic', ticks: { color: palette.textColor }, grid: { color: 'rgba(255, 255, 255, 0.1)' } }, y: { ticks: { color: palette.textColor }, grid: { color: 'rgba(255, 255, 255, 0.1)' } } }, plugins: { legend: { display: false }, tooltip: { callbacks: { title: tooltipTitleCallback, label: (context) => `${context.dataset.label}: ${context.raw.toLocaleString()}` } } } }
            });
        };

        const createBiasChart = (lang) => {
            const ctx = document.getElementById('biasChart').getContext('2d');
            const data = chartData[lang].bias;
            if (biasChart) biasChart.destroy();
            biasChart = new Chart(ctx, {
                type: 'doughnut',
                data: {
                    labels: data.labels,
                    datasets: [{ label: data.datasetLabel, data: [76, 8, 16], backgroundColor: [palette.color1, palette.color2, palette.color3], borderColor: '#2C2F33', borderWidth: 4 }]
                },
                options: { ...chartOptionsTemplate, cutout: '60%', plugins: { legend: { position: 'bottom', labels: { color: palette.textColor, font: { family: "'Inter', 'Noto Sans TC', sans-serif" } } }, tooltip: { callbacks: { title: tooltipTitleCallback, label: (context) => `${context.label}: ${context.raw}%` } } } }
            });
        };

        const recreateCharts = (lang) => {
            createArchChart(lang);
            createDatasetChart(lang);
            createBiasChart(lang);
        };

        document.getElementById('lang-en').addEventListener('click', () => switchLanguage('en'));
        document.getElementById('lang-zh').addEventListener('click', () => switchLanguage('zh'));

        window.onload = () => {
            switchLanguage('en');
        };
    </script>
</body>
</html>
