<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Noise to Photorealism: The Principles of AI Image Generation</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;900&family=Noto+Sans+TC:wght@400;700;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', 'Noto Sans TC', sans-serif;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 500px;
            margin-left: auto;
            margin-right: auto;
            height: 350px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 400px;
            }
        }
        .flow-box {
            border-color: #F9D423;
            background-color: rgba(255, 255, 255, 0.05);
        }
        .flow-arrow {
            color: #F9D423;
        }
        .kpi-card {
            background-color: #2c2f33;
            border-left: 4px solid #FC913A;
        }
        .prompt-card {
             background-color: rgba(255, 255, 255, 0.05);
        }
        .lang-switcher button.active {
            background-color: #FF4E50;
            color: white;
        }
    </style>
</head>
<body class="bg-[#23272A] text-gray-200">

    <div class="container mx-auto p-4 md:p-8">

        <div class="lang-switcher fixed top-4 right-4 z-50 bg-[#2C2F33] rounded-full p-1 shadow-lg">
            <button id="lang-en" class="px-3 py-1 text-sm font-bold rounded-full transition-colors duration-300 active">EN</button>
            <button id="lang-zh" class="px-3 py-1 text-sm font-bold rounded-full transition-colors duration-300">ÁπÅÈ´î</button>
        </div>

        <header class="text-center my-12">
            <h1 data-lang-key="mainTitle" class="text-4xl md:text-6xl font-black tracking-tight text-white leading-tight">From Noise to <span class="text-[#FF4E50]">Photorealism</span></h1>
            <p data-lang-key="mainSubtitle" class="mt-4 text-lg md:text-xl text-gray-400 max-w-3xl mx-auto">An interactive guide to the principles, architectures, and societal impact of modern AI image generation.</p>
        </header>

        <main class="space-y-16">

            <section id="architectures">
                <div class="text-center mb-12">
                    <h2 data-lang-key="section1Title" class="text-3xl font-bold text-white">The Core Engines: Two Competing Philosophies</h2>
                    <p data-lang-key="section1Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">At the heart of AI image generation lie two dominant architectures: Generative Adversarial Networks (GANs) and Diffusion Models. While both can produce stunning results, they operate on fundamentally different principles, leading to a critical trade-off between speed, stability, and control.</p>
                </div>
                <div class="bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8">
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-8 items-center">
                        <div class="text-gray-300">
                            <h3 data-lang-key="section1ChartTitle" class="text-2xl font-bold text-white mb-4">GANs vs. Diffusion Models</h3>
                             <p data-lang-key="section1ChartPara1" class="mb-4">This comparison highlights the key trade-offs. GANs, known for their lightning-fast inference, excel in real-time applications and direct feature editing. However, their adversarial training process is notoriously unstable.</p>
                             <p data-lang-key="section1ChartPara2">In contrast, Diffusion Models offer superior image diversity and training stability, making them the backbone of modern large-scale models like Stable Diffusion. This reliability comes at the cost of a much slower, iterative generation process.</p>
                        </div>
                        <div class="chart-container">
                            <canvas id="archComparisonChart"></canvas>
                        </div>
                    </div>
                </div>
            </section>

            <section id="stylegan-flow">
                 <div class="text-center mb-12">
                    <h2 data-lang-key="section2Title" class="text-3xl font-bold text-white">The Art of Control: Disentangling Features with StyleGAN</h2>
                    <p data-lang-key="section2Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">To generate not just realistic, but controllable faces, NVIDIA's StyleGAN introduced a revolutionary architecture. Its key insight was to separate the abstract "style" of a face from the random noise, allowing for unprecedented, fine-grained editing of semantic features like age, expression, and lighting.</p>
                </div>
                <div class="bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8">
                    <h3 data-lang-key="section2FlowTitle" class="text-2xl font-bold text-white text-center mb-8">StyleGAN's Control Mechanism</h3>
                    <div class="flex flex-col md:flex-row items-center justify-center space-y-4 md:space-y-0 md:space-x-4 text-center">
                        <div class="flow-box border-2 rounded-lg p-4 w-48">
                            <h4 data-lang-key="flowBox1Title" class="font-bold text-lg">Latent Code (z)</h4>
                            <p data-lang-key="flowBox1Para" class="text-sm text-gray-400">A random noise vector</p>
                        </div>
                        <div class="text-4xl flow-arrow font-thin transform md:-translate-y-2 rotate-90 md:rotate-0">&rarr;</div>
                        <div class="flow-box border-2 rounded-lg p-4 w-48">
                            <h4 data-lang-key="flowBox2Title" class="font-bold text-lg">Mapping Network (f)</h4>
                            <p data-lang-key="flowBox2Para" class="text-sm text-gray-400">Transforms z into a disentangled space W</p>
                        </div>
                        <div class="text-4xl flow-arrow font-thin transform md:-translate-y-2 rotate-90 md:rotate-0">&rarr;</div>
                         <div class="flow-box border-2 rounded-lg p-4 w-48">
                            <h4 data-lang-key="flowBox3Title" class="font-bold text-lg">Style Vector (w)</h4>
                            <p data-lang-key="flowBox3Para" class="text-sm text-gray-400">Controls a specific visual style</p>
                        </div>
                        <div class="text-4xl flow-arrow font-thin transform md:-translate-y-2 rotate-90 md:rotate-0">&darr;</div>
                         <div class="flow-box border-2 rounded-lg p-4 w-48">
                            <h4 data-lang-key="flowBox4Title" class="font-bold text-lg">Synthesis Network</h4>
                            <p data-lang-key="flowBox4Para" class="text-sm text-gray-400">Builds the image, injecting style at each layer</p>
                        </div>
                    </div>
                    <p data-lang-key="section2FlowPara" class="text-center mt-8 text-gray-400 max-w-3xl mx-auto">This flow diagram, built with HTML and Tailwind CSS, illustrates the process. The Mapping Network is the key: it creates an intermediate latent space 'W' where different visual attributes are separated. This "disentanglement" is what makes intuitive control possible, allowing a user to change one feature (like a smile) without accidentally altering others (like gender).</p>
                </div>
            </section>

            <section id="prompting">
                <div class="text-center mb-12">
                    <h2 data-lang-key="section3Title" class="text-3xl font-bold text-white">Speaking the AI's Language: The Art of the Prompt</h2>
                    <p data-lang-key="section3Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">Modern models like Stable Diffusion are guided by natural language. The quality of the output is directly tied to the quality of the input "prompt." Effective prompting is a new form of programming, blending artistic direction with technical specification to create a detailed blueprint for the AI.</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
                    <div class="prompt-card rounded-lg p-6">
                        <div class="flex items-center">
                            <span class="text-3xl mr-4">üë§</span>
                            <h3 data-lang-key="promptCard1Title" class="text-xl font-bold text-white">Subject & Style</h3>
                        </div>
                        <p data-lang-key="promptCard1Para" class="mt-2 text-gray-400">Be specific. "A 30-year-old woman with auburn hair" is better than "a woman." Define the medium, e.g., "photorealistic," "oil painting."</p>
                    </div>
                    <div class="prompt-card rounded-lg p-6">
                         <div class="flex items-center">
                            <span class="text-3xl mr-4">üñºÔ∏è</span>
                            <h3 data-lang-key="promptCard2Title" class="text-xl font-bold text-white">Composition & Lighting</h3>
                        </div>
                        <p data-lang-key="promptCard2Para" class="mt-2 text-gray-400">Use photographic terms. "Close-up portrait," "low-angle shot," "cinematic lighting," "soft rim light" guide the AI to professional results.</p>
                    </div>
                    <div class="prompt-card rounded-lg p-6">
                         <div class="flex items-center">
                            <span class="text-3xl mr-4">‚öôÔ∏è</span>
                            <h3 data-lang-key="promptCard3Title" class="text-xl font-bold text-white">Technical Details</h3>
                        </div>
                        <p data-lang-key="promptCard3Para" class="mt-2 text-gray-400">Mimic real-world gear. Adding "shot on Canon 5D, 85mm f/1.4 lens, 8K UHD" pushes the model towards higher fidelity and realism.</p>
                    </div>
                </div>
            </section>


            <section id="data">
                <div class="text-center mb-12">
                    <h2 data-lang-key="section4Title" class="text-3xl font-bold text-white">The Fuel of Creation: The Data Dilemma</h2>
                    <p data-lang-key="section4Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">An AI model is only as good as the data it's trained on. The choice of dataset represents a fundamental trade-off between specialization and generalization, and raises significant ethical questions about copyright, privacy, and bias.</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div class="bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8">
                         <h3 data-lang-key="section4ChartTitle" class="text-2xl font-bold text-white mb-4">Dataset Scale: Curated vs. Web-Scale</h3>
                         <p data-lang-key="section4ChartPara" class="text-gray-300 mb-4">This chart visualizes the staggering difference in scale between a curated, specialized dataset like FFHQ (70,000 images), used to train StyleGAN, and a web-scraped, general-purpose dataset like LAION-5B (5.85 billion image-text pairs), which powers Stable Diffusion. The y-axis uses a logarithmic scale to make this vast difference comprehensible.</p>
                        <div class="chart-container">
                            <canvas id="datasetComparisonChart"></canvas>
                        </div>
                    </div>
                    <div class="bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8 flex flex-col justify-center">
                        <h3 data-lang-key="section4CostTitle" class="text-2xl font-bold text-white mb-6">The Unseen Cost of Scale</h3>
                        <div class="space-y-4">
                            <div>
                                <h4 data-lang-key="section4CostFFHQTitle" class="font-semibold text-[#FF4E50]">FFHQ (Specialist)</h4>
                                <p data-lang-key="section4CostFFHQPara" class="text-gray-400">‚úì High Quality & Resolution<br/>‚úì Cleaned & Curated<br/>‚úì Unparalleled Control</p>
                            </div>
                            <div>
                                <h4 data-lang-key="section4CostLAIONTitle" class="font-semibold text-[#FC913A]">LAION-5B (Generalist)</h4>
                                <p data-lang-key="section4CostLAIONPara" class="text-gray-400">‚úì Massive Diversity<br/>‚úó Copyright & Privacy Issues<br/>‚úó Contains Biased & Harmful Content</p>
                            </div>
                        </div>
                         <p data-lang-key="section4CostPara" class="text-gray-300 mt-6">While LAION-5B enables incredible versatility, its uncurated nature means models inherit the internet's "original sin"‚Äîa chaotic mix of creativity, toxicity, and exploitation, creating major legal and ethical challenges.</p>
                    </div>
                </div>
            </section>
            
            <section id="ethics">
                <div class="text-center mb-12">
                    <h2 data-lang-key="section5Title" class="text-3xl font-bold text-white">The Societal Mirror: Bias, Truth, and Law</h2>
                    <p data-lang-key="section5Para" class="mt-2 text-gray-400 max-w-2xl mx-auto">AI models are not objective; they are a mirror reflecting the biases in their training data. This has profound implications for fairness, trust in digital media, and the ongoing legal battles over copyright and authenticity.</p>
                </div>
                <div class="grid grid-cols-1 lg:grid-cols-3 gap-8">
                    <div class="lg:col-span-2 bg-[#2C2F33] rounded-2xl shadow-2xl p-6 md:p-8">
                         <h3 data-lang-key="section5ChartTitle" class="text-2xl font-bold text-white mb-4">Encoded Bias: A Case Study</h3>
                         <p data-lang-key="section5ChartPara" class="text-gray-300 mb-4">AI models amplify societal stereotypes. When one model was prompted to generate images for professions, the results showed stark gender bias. This donut chart illustrates how a prompt for "a doctor" overwhelmingly produced male images, reflecting and reinforcing outdated stereotypes encoded in the training data.</p>
                        <div class="chart-container max-w-sm">
                            <canvas id="biasChart"></canvas>
                        </div>
                    </div>
                     <div class="space-y-8">
                        <div class="kpi-card p-6 rounded-lg shadow-lg">
                            <h4 data-lang-key="kpi1Title" class="text-lg font-bold text-white">The End of "Photographic Truth"</h4>
                            <p data-lang-key="kpi1Para" class="mt-2 text-gray-300">AI faces are now indistinguishable from real ones, and studies show they are often perceived as <span class="font-bold text-[#FC913A]">more trustworthy</span>. The age-old concept of "seeing is believing" is fundamentally broken.</p>
                        </div>
                        <div class="kpi-card p-6 rounded-lg shadow-lg">
                            <h4 data-lang-key="kpi2Title" class="text-lg font-bold text-white">The Deepfake Dilemma</h4>
                            <p data-lang-key="kpi2Para" class="mt-2 text-gray-300">The ease of creating hyper-realistic fakes for disinformation, fraud, and harassment creates a dangerous asymmetry where creation is far easier and cheaper than detection and defense.</p>
                        </div>
                    </div>
                </div>
            </section>

        </main>

        <footer class="text-center mt-20 py-8 border-t border-gray-700">
            <p data-lang-key="footerText" class="text-gray-500">Infographic generated based on "From Noise to Photorealism" report. All visualizations are rendered using HTML Canvas and Chart.js, with no SVG or Mermaid JS assets used.</p>
        </footer>
    </div>

    <script>
        const translations = {
            en: {
                mainTitle: 'From Noise to <span class="text-[#FF4E50]">Photorealism</span>',
                mainSubtitle: "An interactive guide to the principles, architectures, and societal impact of modern AI image generation.",
                section1Title: "The Core Engines: Two Competing Philosophies",
                section1Para: "At the heart of AI image generation lie two dominant architectures: Generative Adversarial Networks (GANs) and Diffusion Models. While both can produce stunning results, they operate on fundamentally different principles, leading to a critical trade-off between speed, stability, and control.",
                section1ChartTitle: "GANs vs. Diffusion Models",
                section1ChartPara1: "This comparison highlights the key trade-offs. GANs, known for their lightning-fast inference, excel in real-time applications and direct feature editing. However, their adversarial training process is notoriously unstable.",
                section1ChartPara2: "In contrast, Diffusion Models offer superior image diversity and training stability, making them the backbone of modern large-scale models like Stable Diffusion. This reliability comes at the cost of a much slower, iterative generation process.",
                section2Title: "The Art of Control: Disentangling Features with StyleGAN",
                section2Para: "To generate not just realistic, but controllable faces, NVIDIA's StyleGAN introduced a revolutionary architecture. Its key insight was to separate the abstract 'style' of a face from the random noise, allowing for unprecedented, fine-grained editing of semantic features like age, expression, and lighting.",
                section2FlowTitle: "StyleGAN's Control Mechanism",
                flowBox1Title: "Latent Code (z)",
                flowBox1Para: "A random noise vector",
                flowBox2Title: "Mapping Network (f)",
                flowBox2Para: "Transforms z into a disentangled space W",
                flowBox3Title: "Style Vector (w)",
                flowBox3Para: "Controls a specific visual style",
                flowBox4Title: "Synthesis Network",
                flowBox4Para: "Builds the image, injecting style at each layer",
                section2FlowPara: "This flow diagram, built with HTML and Tailwind CSS, illustrates the process. The Mapping Network is the key: it creates an intermediate latent space 'W' where different visual attributes are separated. This 'disentanglement' is what makes intuitive control possible, allowing a user to change one feature (like a smile) without accidentally altering others (like gender).",
                section3Title: "Speaking the AI's Language: The Art of the Prompt",
                section3Para: "Modern models like Stable Diffusion are guided by natural language. The quality of the output is directly tied to the quality of the input 'prompt.' Effective prompting is a new form of programming, blending artistic direction with technical specification to create a detailed blueprint for the AI.",
                promptCard1Title: "Subject & Style",
                promptCard1Para: 'Be specific. "A 30-year-old woman with auburn hair" is better than "a woman." Define the medium, e.g., "photorealistic," "oil painting."',
                promptCard2Title: "Composition & Lighting",
                promptCard2Para: 'Use photographic terms. "Close-up portrait," "low-angle shot," "cinematic lighting," "soft rim light" guide the AI to professional results.',
                promptCard3Title: "Technical Details",
                promptCard3Para: 'Mimic real-world gear. Adding "shot on Canon 5D, 85mm f/1.4 lens, 8K UHD" pushes the model towards higher fidelity and realism.',
                section4Title: "The Fuel of Creation: The Data Dilemma",
                section4Para: "An AI model is only as good as the data it's trained on. The choice of dataset represents a fundamental trade-off between specialization and generalization, and raises significant ethical questions about copyright, privacy, and bias.",
                section4ChartTitle: "Dataset Scale: Curated vs. Web-Scale",
                section4ChartPara: "This chart visualizes the staggering difference in scale between a curated, specialized dataset like FFHQ (70,000 images), used to train StyleGAN, and a web-scraped, general-purpose dataset like LAION-5B (5.85 billion image-text pairs), which powers Stable Diffusion. The y-axis uses a logarithmic scale to make this vast difference comprehensible.",
                section4CostTitle: "The Unseen Cost of Scale",
                section4CostFFHQTitle: "FFHQ (Specialist)",
                section4CostFFHQPara: "‚úì High Quality & Resolution<br/>‚úì Cleaned & Curated<br/>‚úì Unparalleled Control",
                section4CostLAIONTitle: "LAION-5B (Generalist)",
                section4CostLAIONPara: "‚úì Massive Diversity<br/>‚úó Copyright & Privacy Issues<br/>‚úó Contains Biased & Harmful Content",
                section4CostPara: "While LAION-5B enables incredible versatility, its uncurated nature means models inherit the internet's 'original sin'‚Äîa chaotic mix of creativity, toxicity, and exploitation, creating major legal and ethical challenges.",
                section5Title: "The Societal Mirror: Bias, Truth, and Law",
                section5Para: "AI models are not objective; they are a mirror reflecting the biases in their training data. This has profound implications for fairness, trust in digital media, and the ongoing legal battles over copyright and authenticity.",
                section5ChartTitle: "Encoded Bias: A Case Study",
                section5ChartPara: "AI models amplify societal stereotypes. When one model was prompted to generate images for professions, the results showed stark gender bias. This donut chart illustrates how a prompt for 'a doctor' overwhelmingly produced male images, reflecting and reinforcing outdated stereotypes encoded in the training data.",
                kpi1Title: 'The End of "Photographic Truth"',
                kpi1Para: 'AI faces are now indistinguishable from real ones, and studies show they are often perceived as <span class="font-bold text-[#FC913A]">more trustworthy</span>. The age-old concept of "seeing is believing" is fundamentally broken.',
                kpi2Title: "The Deepfake Dilemma",
                kpi2Para: "The ease of creating hyper-realistic fakes for disinformation, fraud, and harassment creates a dangerous asymmetry where creation is far easier and cheaper than detection and defense.",
                footerText: 'Infographic generated based on "From Noise to Photorealism" report. All visualizations are rendered using HTML Canvas and Chart.js, with no SVG or Mermaid JS assets used.',
            },
            zh: {
                mainTitle: 'ÂæûÂô™ËÅ≤Âà∞<span class="text-[#FF4E50]">ÁÖßÁâáÁ¥öÁúüÂØ¶ÊÑü</span>',
                mainSubtitle: "‰∏ÄÂÄãÈóúÊñºÁèæ‰ª£AIÂúñÂÉèÁîüÊàêÁöÑÂéüÁêÜ„ÄÅÊû∂ÊßãÂíåÁ§æÊúÉÂΩ±ÈüøÁöÑ‰∫íÂãïÊåáÂçó„ÄÇ",
                section1Title: "Ê†∏ÂøÉÂºïÊìéÔºöÂÖ©Á®ÆÁ´∂Áà≠Âì≤Â≠∏",
                section1Para: "Âú®AIÂúñÂÉèÁîüÊàêÁöÑÊ†∏ÂøÉÔºåÂ≠òÂú®ÂÖ©Á®Æ‰∏ªÂ∞éÊû∂ÊßãÔºöÁîüÊàêÂ∞çÊäóÁ∂≤Áµ°ÔºàGANsÔºâÂíåÊì¥Êï£Ê®°Âûã„ÄÇÈõñÁÑ∂ÂÖ©ËÄÖÈÉΩËÉΩÁî¢ÁîüÈ©ö‰∫∫ÁöÑÁµêÊûúÔºå‰ΩÜÂÆÉÂÄëÁöÑÈÅã‰ΩúÂéüÁêÜÊ†πÊú¨‰∏çÂêåÔºåÂ∞éËá¥Âú®ÈÄüÂ∫¶„ÄÅÁ©©ÂÆöÊÄßÂíåÊéßÂà∂‰πãÈñìÂ≠òÂú®ÈóúÈçµÁöÑÊ¨äË°°„ÄÇ",
                section1ChartTitle: "GANs vs. Êì¥Êï£Ê®°Âûã",
                section1ChartPara1: "Ê≠§ÊØîËºÉÁ™ÅÈ°Ø‰∫ÜÈóúÈçµÁöÑÊ¨äË°°„ÄÇ‰ª•ÂÖ∂ÈñÉÈõªËà¨ÁöÑÊé®ÁêÜÈÄüÂ∫¶ËÄåËÅûÂêçÁöÑGANÔºåÂú®ÂØ¶ÊôÇÊáâÁî®ÂíåÁõ¥Êé•ÁâπÂæµÁ∑®ËºØÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÂÖ∂Â∞çÊäóÊÄßË®ìÁ∑¥ÈÅéÁ®ãÊòØÂá∫‰∫ÜÂêçÁöÑ‰∏çÁ©©ÂÆö„ÄÇ",
                section1ChartPara2: "Áõ∏ÊØî‰πã‰∏ãÔºåÊì¥Êï£Ê®°ÂûãÊèê‰æõ‰∫ÜÂçìË∂äÁöÑÂúñÂÉèÂ§öÊ®£ÊÄßÂíåË®ìÁ∑¥Á©©ÂÆöÊÄßÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂÉèStable DiffusionÈÄôÊ®£Áèæ‰ª£Â§ßË¶èÊ®°Ê®°ÂûãÁöÑÊîØÊü±„ÄÇÈÄôÁ®ÆÂèØÈù†ÊÄßÊòØ‰ª•‰∏ÄÂÄãÊõ¥ÊÖ¢„ÄÅËø≠‰ª£ÁöÑÁîüÊàêÈÅéÁ®ãÁÇ∫‰ª£ÂÉπÁöÑ„ÄÇ",
                section2Title: "ÊéßÂà∂ÁöÑËóùË°ìÔºöÁî®StyleGANËß£ËÄ¶ÁâπÂæµ",
                section2Para: "ÁÇ∫‰∫ÜÁîüÊàê‰∏çÂÉÖÁúüÂØ¶ÔºåËÄå‰∏îÂèØÊéßÁöÑ‰∫∫ËáâÔºåNVIDIAÁöÑStyleGANÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÈù©ÂëΩÊÄßÁöÑÊû∂Êßã„ÄÇÂÖ∂ÈóúÈçµÊ¥ûË¶ãÊòØÂ∞á‰∫∫ËáâÁöÑÊäΩË±°„ÄåÈ¢®Ê†º„ÄçËàáÈö®Ê©üÂô™ËÅ≤ÂàÜÈñãÔºåÂæûËÄåÂØ¶ÁèæÂ∞çÂπ¥ÈΩ°„ÄÅË°®ÊÉÖÂíåÂÖâÁÖßÁ≠âË™ûÁæ©ÁâπÂæµÂâçÊâÄÊú™ÊúâÁöÑÁ≤æÁ¥∞Á∑®ËºØ„ÄÇ",
                section2FlowTitle: "StyleGANÁöÑÊéßÂà∂Ê©üÂà∂",
                flowBox1Title: "ÊΩõÂú®‰ª£Á¢º (z)",
                flowBox1Para: "‰∏ÄÂÄãÈö®Ê©üÂô™ËÅ≤ÂêëÈáè",
                flowBox2Title: "Êò†Â∞ÑÁ∂≤Áµ° (f)",
                flowBox2Para: "Â∞ázËΩâÊèõÁÇ∫‰∏ÄÂÄãËß£ËÄ¶ÁöÑÁ©∫ÈñìW",
                flowBox3Title: "È¢®Ê†ºÂêëÈáè (w)",
                flowBox3Para: "ÊéßÂà∂ÁâπÂÆöÁöÑË¶ñË¶∫È¢®Ê†º",
                flowBox4Title: "ÂêàÊàêÁ∂≤Áµ°",
                flowBox4Para: "Ê≥®ÂÖ•È¢®Ê†ºÔºåÈÄêÂ±§ÊßãÂª∫ÂúñÂÉè",
                section2FlowPara: "ÈÄôÂÄãÁî®HTMLÂíåTailwind CSSÊßãÂª∫ÁöÑÊµÅÁ®ãÂúñË™™Êòé‰∫ÜÈÄôÂÄãÈÅéÁ®ã„ÄÇÊò†Â∞ÑÁ∂≤Áµ°ÊòØÈóúÈçµÔºöÂÆÉÂâµÂª∫‰∫Ü‰∏ÄÂÄã‰∏≠ÈñìÊΩõÂú®Á©∫Èñì'W'ÔºåÂÖ∂‰∏≠‰∏çÂêåÁöÑË¶ñË¶∫Â±¨ÊÄßË¢´ÂàÜÈõ¢Èñã‰æÜ„ÄÇÈÄôÁ®Æ„ÄåËß£ËÄ¶„Äç‰ΩøÂæóÁõ¥ËßÄÁöÑÊéßÂà∂ÊàêÁÇ∫ÂèØËÉΩÔºåÂÖÅË®±Áî®Êà∂Êõ¥Êîπ‰∏ÄÂÄãÁâπÂæµÔºàÂ¶ÇÂæÆÁ¨ëÔºâËÄå‰∏çÊúÉÊÑèÂ§ñÂú∞ÊîπËÆäÂÖ∂‰ªñÁâπÂæµÔºàÂ¶ÇÊÄßÂà•Ôºâ„ÄÇ",
                section3Title: "Ë™™AIÁöÑË™ûË®ÄÔºöÊèêÁ§∫Ë©ûÁöÑËóùË°ì",
                section3Para: "ÂÉèStable DiffusionÈÄôÊ®£ÁöÑÁèæ‰ª£Ê®°ÂûãÊòØÁî±Ëá™ÁÑ∂Ë™ûË®ÄÂºïÂ∞éÁöÑ„ÄÇËº∏Âá∫ÁöÑË≥™ÈáèËàáËº∏ÂÖ•„ÄåÊèêÁ§∫Ë©û„ÄçÁöÑË≥™ÈáèÁõ¥Êé•Áõ∏Èóú„ÄÇÊúâÊïàÁöÑÊèêÁ§∫Ë©ûÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑÁ∑®Á®ãÂΩ¢ÂºèÔºåÂ∞áËóùË°ìÊåáÂ∞éËàáÊäÄË°ìË¶èÁØÑÁõ∏ÁµêÂêàÔºåÁÇ∫AIÂâµÂª∫Ë©≥Á¥∞ÁöÑËóçÂúñ„ÄÇ",
                promptCard1Title: "‰∏ªÈ´îËàáÈ¢®Ê†º",
                promptCard1Para: 'Ë¶ÅÂÖ∑È´î„ÄÇ„Äå‰∏Ä‰Ωç‰∏âÂçÅÂ§öÊ≠≤„ÄÅÁïôËëóËµ§Ë§êËâ≤È†≠È´ÆÁöÑÂ•≥ÊÄß„ÄçÂãùÈÅé„Äå‰∏Ä‰ΩçÂ•≥ÊÄß„Äç„ÄÇÂÆöÁæ©Â™í‰ªãÔºå‰æãÂ¶Ç„ÄåÁÖßÁâáÁ¥öÁúüÂØ¶ÊÑü„Äç„ÄÅ„ÄåÊ≤πÁï´„Äç„ÄÇ',
                promptCard2Title: "ÊßãÂúñËàáÂÖâÁÖß",
                promptCard2Para: '‰ΩøÁî®ÊîùÂΩ±Ë°ìË™û„ÄÇ„ÄåÁâπÂØ´ËÇñÂÉè„Äç„ÄÅ„Äå‰ΩéËßíÂ∫¶ÊãçÊîù„Äç„ÄÅ„ÄåÈõªÂΩ±Á¥öÂÖâÊïà„Äç„ÄÅ„ÄåÊüîÂíåÁöÑËº™ÂªìÂÖâ„ÄçËÉΩÂºïÂ∞éAIÈÅîÂà∞Â∞àÊ•≠ÊïàÊûú„ÄÇ',
                promptCard3Title: "ÊäÄË°ìÁ¥∞ÁØÄ",
                promptCard3Para: 'Ê®°‰ªøÁúüÂØ¶‰∏ñÁïåÁöÑË®≠ÂÇô„ÄÇÊ∑ªÂä†„Äå‰ΩøÁî®Canon 5DÔºå85mm f/1.4Èè°È†≠ÊãçÊîùÔºå8K UHD„ÄçËÉΩ‰øÉ‰ΩøÊ®°ÂûãÈÅîÂà∞Êõ¥È´òÁöÑ‰øùÁúüÂ∫¶ÂíåÁúüÂØ¶ÊÑü„ÄÇ',
                section4Title: "ÂâµÈÄ†ÁöÑÁáÉÊñôÔºöÊï∏ÊìöÂõ∞Â¢É",
                section4Para: "‰∏ÄÂÄãAIÊ®°ÂûãÁöÑÂ•ΩÂ£ûÂèñÊ±∫ÊñºÂÖ∂Ë®ìÁ∑¥Êï∏Êìö„ÄÇÊï∏ÊìöÈõÜÁöÑÈÅ∏Êìá‰ª£Ë°®‰∫ÜÂ∞àÊ•≠ÂåñËàáÊ≥õÂåñ‰πãÈñìÁöÑÂü∫Êú¨Ê¨äË°°Ôºå‰∏¶ÂºïÁôº‰∫ÜÈóúÊñºÁâàÊ¨ä„ÄÅÈö±ÁßÅÂíåÂÅèË¶ãÁöÑÈáçÂ§ßÂÄ´ÁêÜÂïèÈ°å„ÄÇ",
                section4ChartTitle: "Êï∏ÊìöÈõÜË¶èÊ®°ÔºöÁ≤æÈÅ∏ vs. Á∂≤Áµ°Ë¶èÊ®°",
                section4ChartPara: "Ê≠§ÂúñË°®ÂèØË¶ñÂåñ‰∫ÜÁ≤æÈÅ∏ÁöÑÂ∞àÊ•≠Êï∏ÊìöÈõÜÔºàÂ¶ÇÁî®ÊñºË®ìÁ∑¥StyleGANÁöÑFFHQÔºå7Ëê¨ÂºµÂúñÂÉèÔºâËàáÁ∂≤Áµ°ÊäìÂèñÁöÑÈÄöÁî®Êï∏ÊìöÈõÜÔºàÂ¶ÇÈ©ÖÂãïStable DiffusionÁöÑLAION-5BÔºå58.5ÂÑÑÂÄãÂúñÊñáÂ∞çÔºâ‰πãÈñìÈ©ö‰∫∫ÁöÑË¶èÊ®°Â∑ÆÁï∞„ÄÇYËª∏‰ΩøÁî®Â∞çÊï∏ÂàªÂ∫¶Ôºå‰ª•‰ΩøÈÄôÁ®ÆÂ∑®Â§ßÁöÑÂ∑ÆÁï∞ÊòìÊñºÁêÜËß£„ÄÇ",
                section4CostTitle: "Ë¶èÊ®°ÁöÑÁÑ°ÂΩ¢ÊàêÊú¨",
                section4CostFFHQTitle: "FFHQ (Â∞àÂÆ∂)",
                section4CostFFHQPara: "‚úì È´òË≥™ÈáèËàáÈ´òÂàÜËæ®Áéá<br/>‚úì Á∂ìÈÅéÊ∏ÖÁêÜËàáÁ≠ñÂäÉ<br/>‚úì ÁÑ°ËàáÂÄ´ÊØîÁöÑÊéßÂà∂Âäõ",
                section4CostLAIONTitle: "LAION-5B (ÈÄöÊâç)",
                section4CostLAIONPara: "‚úì Â∑®Â§ßÁöÑÂ§öÊ®£ÊÄß<br/>‚úó ÁâàÊ¨äËàáÈö±ÁßÅÂïèÈ°å<br/>‚úó ÂåÖÂê´ÂÅèË¶ãËàáÊúâÂÆ≥ÂÖßÂÆπ",
                section4CostPara: "ÈõñÁÑ∂LAION-5BÂØ¶Áèæ‰∫Ü‰ª§‰∫∫Èõ£‰ª•ÁΩÆ‰ø°ÁöÑÂ§öÂäüËÉΩÊÄßÔºå‰ΩÜÂÖ∂Êú™Á∂ìÊï¥ÁêÜÁöÑÊÄßË≥™ÊÑèÂë≥ËëóÊ®°ÂûãÁπºÊâø‰∫Ü‰∫íËÅØÁ∂≤ÁöÑ„ÄåÂéüÁΩ™„Äç‚Äî‚Äî‰∏ÄÁ®ÆÂâµÈÄ†Âäõ„ÄÅÊØíÊÄßÂíåÂâùÂâäÁöÑÊ∑∑‰∫ÇÁµêÂêàÈ´îÔºåÂæûËÄåÁî¢Áîü‰∫ÜÈáçÂ§ßÁöÑÊ≥ïÂæãÂíåÂÄ´ÁêÜÊåëÊà∞„ÄÇ",
                section5Title: "Á§æÊúÉÁöÑÈè°Â≠êÔºöÂÅèË¶ã„ÄÅÁúüÁõ∏ËàáÊ≥ïÂæã",
                section5Para: "AIÊ®°Âûã‰∏¶ÈùûÂÆ¢ËßÄÔºõÂÆÉÂÄëÊòØÂèçÊò†ÂÖ∂Ë®ìÁ∑¥Êï∏Êìö‰∏≠ÂÅèË¶ãÁöÑ‰∏ÄÈù¢Èè°Â≠ê„ÄÇÈÄôÂ∞çÂÖ¨Âπ≥ÊÄß„ÄÅÂ∞çÊï∏Â≠óÂ™íÈ´îÁöÑ‰ø°‰ªª‰ª•ÂèäÊ≠£Âú®ÈÄ≤Ë°åÁöÑÈóúÊñºÁâàÊ¨äÂíåÁúüÂØ¶ÊÄßÁöÑÊ≥ïÂæãÈ¨•Áà≠Áî¢Áîü‰∫ÜÊ∑±ÈÅ†ÁöÑÂΩ±Èüø„ÄÇ",
                section5ChartTitle: "Á∑®Á¢ºÁöÑÂÅèË¶ãÔºöÊ°à‰æãÁ†îÁ©∂",
                section5ChartPara: "AIÊ®°ÂûãÊîæÂ§ß‰∫ÜÁ§æÊúÉÂàªÊùøÂç∞Ë±°„ÄÇÁï∂‰∏ÄÂÄãÊ®°ÂûãË¢´ÊèêÁ§∫ÁîüÊàêËÅ∑Ê•≠ÂúñÂÉèÊôÇÔºåÁµêÊûúÈ°ØÁ§∫Âá∫ÊòéÈ°ØÁöÑÊÄßÂà•ÂÅèË¶ã„ÄÇÈÄôÂÄãÁîúÁîúÂúàÂúñË™™Êòé‰∫Ü„ÄåÈÜ´Áîü„ÄçÁöÑÊèêÁ§∫Ë©ûÂ¶Ç‰ΩïÁµïÂ§ßÂ§öÊï∏Âú∞Áî¢Áîü‰∫ÜÁî∑ÊÄßÂúñÂÉèÔºåÂèçÊò†‰∏¶Âä†Âº∑‰∫ÜÁ∑®Á¢ºÂú®Ë®ìÁ∑¥Êï∏Êìö‰∏≠ÁöÑÈÅéÊôÇÂàªÊùøÂç∞Ë±°„ÄÇ",
                kpi1Title: '‚ÄúÊîùÂΩ±ÁúüÂØ¶ÊÄß‚ÄùÁöÑÁµÇÁµê',
                kpi1Para: 'AI‰∫∫ËáâÁèæÂú®ËàáÁúü‰∫∫ÁÑ°Ê≥ïÂçÄÂàÜÔºåÁ†îÁ©∂Ë°®ÊòéÂÆÉÂÄëÈÄöÂ∏∏Ë¢´Ë™çÁÇ∫<span class="font-bold text-[#FC913A]">Êõ¥ÂÄºÂæó‰ø°Ë≥¥</span>„ÄÇ„ÄåÁúºË¶ãÁÇ∫ÂØ¶„ÄçÈÄôÂÄãÂè§ËÄÅÁöÑËßÄÂøµÂ∑≤ÂæûÊ†πÊú¨‰∏äË¢´ÊâìÁ†¥„ÄÇ',
                kpi2Title: "Ê∑±Â∫¶ÂÅΩÈÄ†ÁöÑÂõ∞Â¢É",
                kpi2Para: "ËºïÊòìÂâµÂª∫Áî®ÊñºËôõÂÅá‰ø°ÊÅØ„ÄÅÊ¨∫Ë©êÂíåÈ®∑ÊìæÁöÑË∂ÖÁèæÂØ¶ÂÅΩÈÄ†ÂìÅÔºåÈÄ†Êàê‰∫Ü‰∏ÄÁ®ÆÂç±Èö™ÁöÑ‰∏çÂ∞çÁ®±ÊÄßÔºåÂç≥ÂâµÈÄ†ÈÅ†ÊØîÊ™¢Ê∏¨ÂíåÈò≤Á¶¶Êõ¥ÂÆπÊòì„ÄÅÊõ¥‰æøÂÆú„ÄÇ",
                footerText: 'Ë≥áË®äÂúñË°®Âü∫Êñº„ÄäÂæûÂô™ËÅ≤Âà∞ÁÖßÁâáÁ¥öÁúüÂØ¶ÊÑü„ÄãÂ†±ÂëäÁîüÊàê„ÄÇÊâÄÊúâË¶ñË¶∫ÂåñÂùá‰ΩøÁî®HTML CanvasÂíåChart.jsÊ∏≤ÊüìÔºåÊú™‰ΩøÁî®SVGÊàñMermaid JSË≥áÁî¢„ÄÇ',
            }
        };

        const chartData = {
            en: {
                arch: {
                    labels: ['Image Quality', 'Training Stability', 'Inference Speed', 'Controllability', 'Diversity'],
                    datasets: [{ label: 'Diffusion Models' }, { label: 'GANs' }]
                },
                dataset: {
                    labels: ['FFHQ (Curated)', 'LAION-5B (Web-Scale)'],
                    datasetLabel: 'Number of Image-Text Pairs'
                },
                bias: {
                    labels: ['Male Representation', 'Female Representation', 'Other/Unspecified'],
                    datasetLabel: 'Gender Representation for "Doctor" Prompt'
                }
            },
            zh: {
                arch: {
                    labels: ['ÂúñÂÉèË≥™Èáè', 'Ë®ìÁ∑¥Á©©ÂÆöÊÄß', 'Êé®ÁêÜÈÄüÂ∫¶', 'ÂèØÊéßÊÄß', 'Â§öÊ®£ÊÄß'],
                    datasets: [{ label: 'Êì¥Êï£Ê®°Âûã' }, { label: 'ÁîüÊàêÂ∞çÊäóÁ∂≤Áµ°' }]
                },
                dataset: {
                    labels: ['FFHQ (Á≤æÈÅ∏)', 'LAION-5B (Á∂≤Áµ°Ë¶èÊ®°)'],
                    datasetLabel: 'ÂúñÊñáÂ∞çÊï∏Èáè'
                },
                bias: {
                    labels: ['Áî∑ÊÄß‰ª£Ë°®ÊÄß', 'Â•≥ÊÄß‰ª£Ë°®ÊÄß', 'ÂÖ∂‰ªñ/Êú™ÊåáÂÆö'],
                    datasetLabel: '‚ÄúÈÜ´Áîü‚ÄùÊèêÁ§∫Ë©ûÁöÑÊÄßÂà•‰ª£Ë°®ÊÄß'
                }
            }
        };

        let currentLang = 'en';
        let archChart, datasetChart, biasChart;

        const switchLanguage = (lang) => {
            currentLang = lang;
            document.querySelectorAll('[data-lang-key]').forEach(el => {
                const key = el.getAttribute('data-lang-key');
                if (translations[lang][key]) {
                    el.innerHTML = translations[lang][key];
                }
            });

            document.getElementById('lang-en').classList.toggle('active', lang === 'en');
            document.getElementById('lang-zh').classList.toggle('active', lang === 'zh');
            
            recreateCharts(lang);
        };
        
        const tooltipTitleCallback = (tooltipItems) => {
            const item = tooltipItems[0];
            let label = item.chart.data.labels[item.dataIndex];
            if (Array.isArray(label)) {
              return label.join(' ');
            } else {
              return label;
            }
        };

        const chartOptionsTemplate = {
            responsive: true,
            maintainAspectRatio: false,
            plugins: {
                legend: {
                    labels: {
                        color: '#E1F5C4',
                        font: {
                            family: "'Inter', 'Noto Sans TC', sans-serif"
                        }
                    }
                },
                tooltip: {
                    callbacks: {
                        title: tooltipTitleCallback
                    }
                }
            }
        };

        const palette = {
            color1: '#FF4E50',
            color2: '#FC913A',
            color3: '#F9D423',
            textColor: '#E1F5C4'
        };

        const createArchChart = (lang) => {
            const ctx = document.getElementById('archComparisonChart').getContext('2d');
            const data = chartData[lang].arch;
            if (archChart) archChart.destroy();
            archChart = new Chart(ctx, {
                type: 'radar',
                data: {
                    labels: data.labels,
                    datasets: [{
                        label: data.datasets[0].label,
                        data: [9, 9, 2, 6, 9],
                        backgroundColor: 'rgba(255, 78, 80, 0.2)',
                        borderColor: palette.color1,
                        pointBackgroundColor: palette.color1,
                    }, {
                        label: data.datasets[1].label,
                        data: [8, 3, 9, 8, 6],
                        backgroundColor: 'rgba(252, 145, 58, 0.2)',
                        borderColor: palette.color2,
                        pointBackgroundColor: palette.color2,
                    }]
                },
                options: { ...chartOptionsTemplate, scales: { r: { angleLines: { color: 'rgba(255, 255, 255, 0.2)' }, grid: { color: 'rgba(255, 255, 255, 0.2)' }, pointLabels: { color: palette.textColor, font: { size: 12, family: "'Inter', 'Noto Sans TC', sans-serif" } }, ticks: { color: palette.textColor, backdropColor: 'transparent', stepSize: 2 } } } }
            });
        };

        const createDatasetChart = (lang) => {
            const ctx = document.getElementById('datasetComparisonChart').getContext('2d');
            const data = chartData[lang].dataset;
            if (datasetChart) datasetChart.destroy();
            datasetChart = new Chart(ctx, {
                type: 'bar',
                data: {
                    labels: data.labels,
                    datasets: [{ label: data.datasetLabel, data: [70000, 5850000000], backgroundColor: [palette.color1, palette.color2] }]
                },
                options: { ...chartOptionsTemplate, indexAxis: 'y', scales: { x: { type: 'logarithmic', ticks: { color: palette.textColor }, grid: { color: 'rgba(255, 255, 255, 0.1)' } }, y: { ticks: { color: palette.textColor }, grid: { color: 'rgba(255, 255, 255, 0.1)' } } }, plugins: { legend: { display: false }, tooltip: { callbacks: { title: tooltipTitleCallback, label: (context) => `${context.dataset.label}: ${context.raw.toLocaleString()}` } } } }
            });
        };

        const createBiasChart = (lang) => {
            const ctx = document.getElementById('biasChart').getContext('2d');
            const data = chartData[lang].bias;
            if (biasChart) biasChart.destroy();
            biasChart = new Chart(ctx, {
                type: 'doughnut',
                data: {
                    labels: data.labels,
                    datasets: [{ label: data.datasetLabel, data: [76, 8, 16], backgroundColor: [palette.color1, palette.color2, palette.color3], borderColor: '#2C2F33', borderWidth: 4 }]
                },
                options: { ...chartOptionsTemplate, cutout: '60%', plugins: { legend: { position: 'bottom', labels: { color: palette.textColor, font: { family: "'Inter', 'Noto Sans TC', sans-serif" } } }, tooltip: { callbacks: { title: tooltipTitleCallback, label: (context) => `${context.label}: ${context.raw}%` } } } }
            });
        };

        const recreateCharts = (lang) => {
            createArchChart(lang);
            createDatasetChart(lang);
            createBiasChart(lang);
        };

        document.getElementById('lang-en').addEventListener('click', () => switchLanguage('en'));
        document.getElementById('lang-zh').addEventListener('click', () => switchLanguage('zh'));

        window.onload = () => {
            switchLanguage('en');
        };
    </script>
</body>
</html>
